{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def input_prep_fn(x):\n",
    "    x = x.reshape((x.shape[0], 28, 28, 1)) / 255.\n",
    "    return np.where(x > .5, 1.0, 0.0).astype('float32')\n",
    "\n",
    "\n",
    "# use on MNIST data just for demo\n",
    "(X0, L0), (X1, L1) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "num_classes = 10\n",
    "L0 = tf.one_hot(L0, num_classes)\n",
    "L1 = tf.one_hot(L1, num_classes)\n",
    "\n",
    "X0 = input_prep_fn(X0)\n",
    "X1 = input_prep_fn(X1)\n",
    "\n",
    "# code from: https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md\n",
    "MODEL_PERFORMANCE_METRICS = [\n",
    "    # make sure your classes are one-hot encoded\n",
    "    tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.AUC(name='prc', curve='PR'), # precision recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the below, it is just a basic MLP to demonstrate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp():\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "            tf.keras.layers.Dropout(rate=0.2),\n",
    "            tf.keras.layers.Dense(units=10, activation='softmax'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def train_mlp(mlp):\n",
    "    batch_size = 100\n",
    "    num_epochs = 10\n",
    "    \n",
    "    mlp.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=MODEL_PERFORMANCE_METRICS,\n",
    "    )\n",
    "\n",
    "    history = mlp.fit(\n",
    "        x=X0,\n",
    "        y=L0,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.2,\n",
    "        verbose=1,\n",
    "    )\n",
    "    \n",
    "    return mlp, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "480/480 [==============================] - 5s 6ms/step - loss: 0.3683 - accuracy: 0.9151 - precision: 0.9510 - recall: 0.8805 - auc: 0.9938 - prc: 0.9697 - val_loss: 0.1864 - val_accuracy: 0.9480 - val_precision: 0.9620 - val_recall: 0.9339 - val_auc: 0.9969 - val_prc: 0.9855\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.1720 - accuracy: 0.9505 - precision: 0.9626 - recall: 0.9395 - auc: 0.9971 - prc: 0.9864 - val_loss: 0.1350 - val_accuracy: 0.9603 - val_precision: 0.9682 - val_recall: 0.9518 - val_auc: 0.9981 - val_prc: 0.9914\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.1189 - accuracy: 0.9649 - precision: 0.9723 - recall: 0.9579 - auc: 0.9984 - prc: 0.9928 - val_loss: 0.1125 - val_accuracy: 0.9664 - val_precision: 0.9719 - val_recall: 0.9611 - val_auc: 0.9984 - val_prc: 0.9934\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0901 - accuracy: 0.9738 - precision: 0.9785 - recall: 0.9691 - auc: 0.9989 - prc: 0.9953 - val_loss: 0.0997 - val_accuracy: 0.9688 - val_precision: 0.9742 - val_recall: 0.9643 - val_auc: 0.9986 - val_prc: 0.9943\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0706 - accuracy: 0.9783 - precision: 0.9827 - recall: 0.9751 - auc: 0.9994 - prc: 0.9971 - val_loss: 0.0918 - val_accuracy: 0.9728 - val_precision: 0.9766 - val_recall: 0.9698 - val_auc: 0.9985 - val_prc: 0.9945\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0569 - accuracy: 0.9827 - precision: 0.9857 - recall: 0.9803 - auc: 0.9995 - prc: 0.9980 - val_loss: 0.0858 - val_accuracy: 0.9752 - val_precision: 0.9790 - val_recall: 0.9727 - val_auc: 0.9983 - val_prc: 0.9947\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0462 - accuracy: 0.9864 - precision: 0.9885 - recall: 0.9838 - auc: 0.9998 - prc: 0.9988 - val_loss: 0.0899 - val_accuracy: 0.9747 - val_precision: 0.9779 - val_recall: 0.9721 - val_auc: 0.9981 - val_prc: 0.9935\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0400 - accuracy: 0.9879 - precision: 0.9900 - recall: 0.9859 - auc: 0.9998 - prc: 0.9992 - val_loss: 0.0863 - val_accuracy: 0.9745 - val_precision: 0.9774 - val_recall: 0.9728 - val_auc: 0.9980 - val_prc: 0.9940\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0317 - accuracy: 0.9906 - precision: 0.9923 - recall: 0.9893 - auc: 0.9999 - prc: 0.9994 - val_loss: 0.0901 - val_accuracy: 0.9743 - val_precision: 0.9766 - val_recall: 0.9723 - val_auc: 0.9978 - val_prc: 0.9935\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0286 - accuracy: 0.9911 - precision: 0.9923 - recall: 0.9903 - auc: 0.9999 - prc: 0.9995 - val_loss: 0.0910 - val_accuracy: 0.9753 - val_precision: 0.9775 - val_recall: 0.9729 - val_auc: 0.9977 - val_prc: 0.9929\n",
      "Epoch 1/10\n",
      "480/480 [==============================] - 3s 5ms/step - loss: 0.3734 - accuracy: 0.9138 - precision: 0.9510 - recall: 0.8773 - auc: 0.9938 - prc: 0.9691 - val_loss: 0.1870 - val_accuracy: 0.9475 - val_precision: 0.9609 - val_recall: 0.9351 - val_auc: 0.9967 - val_prc: 0.9854\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 2s 5ms/step - loss: 0.1677 - accuracy: 0.9507 - precision: 0.9633 - recall: 0.9400 - auc: 0.9974 - prc: 0.9875 - val_loss: 0.1297 - val_accuracy: 0.9632 - val_precision: 0.9705 - val_recall: 0.9555 - val_auc: 0.9980 - val_prc: 0.9916\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.1162 - accuracy: 0.9663 - precision: 0.9739 - recall: 0.9599 - auc: 0.9985 - prc: 0.9931 - val_loss: 0.1084 - val_accuracy: 0.9687 - val_precision: 0.9743 - val_recall: 0.9631 - val_auc: 0.9985 - val_prc: 0.9935\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 2s 5ms/step - loss: 0.0866 - accuracy: 0.9740 - precision: 0.9789 - recall: 0.9696 - auc: 0.9992 - prc: 0.9959 - val_loss: 0.1006 - val_accuracy: 0.9706 - val_precision: 0.9749 - val_recall: 0.9664 - val_auc: 0.9985 - val_prc: 0.9939\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0695 - accuracy: 0.9792 - precision: 0.9830 - recall: 0.9760 - auc: 0.9994 - prc: 0.9972 - val_loss: 0.0932 - val_accuracy: 0.9710 - val_precision: 0.9749 - val_recall: 0.9673 - val_auc: 0.9987 - val_prc: 0.9946\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0559 - accuracy: 0.9834 - precision: 0.9861 - recall: 0.9804 - auc: 0.9996 - prc: 0.9981 - val_loss: 0.0876 - val_accuracy: 0.9735 - val_precision: 0.9762 - val_recall: 0.9716 - val_auc: 0.9985 - val_prc: 0.9947\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 2s 5ms/step - loss: 0.0458 - accuracy: 0.9864 - precision: 0.9886 - recall: 0.9840 - auc: 0.9997 - prc: 0.9988 - val_loss: 0.0905 - val_accuracy: 0.9725 - val_precision: 0.9761 - val_recall: 0.9700 - val_auc: 0.9982 - val_prc: 0.9939\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.9890 - precision: 0.9903 - recall: 0.9873 - auc: 0.9999 - prc: 0.9993 - val_loss: 0.0854 - val_accuracy: 0.9739 - val_precision: 0.9763 - val_recall: 0.9725 - val_auc: 0.9983 - val_prc: 0.9945\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0302 - accuracy: 0.9908 - precision: 0.9921 - recall: 0.9896 - auc: 0.9999 - prc: 0.9994 - val_loss: 0.0874 - val_accuracy: 0.9747 - val_precision: 0.9768 - val_recall: 0.9736 - val_auc: 0.9981 - val_prc: 0.9941\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0264 - accuracy: 0.9924 - precision: 0.9936 - recall: 0.9915 - auc: 0.9999 - prc: 0.9996 - val_loss: 0.0891 - val_accuracy: 0.9747 - val_precision: 0.9769 - val_recall: 0.9732 - val_auc: 0.9978 - val_prc: 0.9927\n",
      "Epoch 1/10\n",
      "480/480 [==============================] - 4s 5ms/step - loss: 0.3650 - accuracy: 0.9166 - precision: 0.9522 - recall: 0.8807 - auc: 0.9940 - prc: 0.9707 - val_loss: 0.1845 - val_accuracy: 0.9458 - val_precision: 0.9621 - val_recall: 0.9336 - val_auc: 0.9970 - val_prc: 0.9859\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.1668 - accuracy: 0.9519 - precision: 0.9636 - recall: 0.9407 - auc: 0.9973 - prc: 0.9874 - val_loss: 0.1343 - val_accuracy: 0.9599 - val_precision: 0.9684 - val_recall: 0.9513 - val_auc: 0.9979 - val_prc: 0.9911\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.1167 - accuracy: 0.9672 - precision: 0.9737 - recall: 0.9597 - auc: 0.9985 - prc: 0.9931 - val_loss: 0.1108 - val_accuracy: 0.9661 - val_precision: 0.9722 - val_recall: 0.9607 - val_auc: 0.9983 - val_prc: 0.9932\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0865 - accuracy: 0.9740 - precision: 0.9791 - recall: 0.9693 - auc: 0.9991 - prc: 0.9959 - val_loss: 0.0977 - val_accuracy: 0.9702 - val_precision: 0.9748 - val_recall: 0.9652 - val_auc: 0.9984 - val_prc: 0.9941\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0712 - accuracy: 0.9784 - precision: 0.9830 - recall: 0.9745 - auc: 0.9993 - prc: 0.9970 - val_loss: 0.0947 - val_accuracy: 0.9711 - val_precision: 0.9747 - val_recall: 0.9681 - val_auc: 0.9983 - val_prc: 0.9939\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0554 - accuracy: 0.9839 - precision: 0.9865 - recall: 0.9809 - auc: 0.9996 - prc: 0.9982 - val_loss: 0.0886 - val_accuracy: 0.9716 - val_precision: 0.9759 - val_recall: 0.9694 - val_auc: 0.9985 - val_prc: 0.9947\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0470 - accuracy: 0.9858 - precision: 0.9879 - recall: 0.9835 - auc: 0.9997 - prc: 0.9986 - val_loss: 0.0859 - val_accuracy: 0.9726 - val_precision: 0.9760 - val_recall: 0.9711 - val_auc: 0.9983 - val_prc: 0.9943\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0388 - accuracy: 0.9887 - precision: 0.9901 - recall: 0.9872 - auc: 0.9998 - prc: 0.9990 - val_loss: 0.0878 - val_accuracy: 0.9737 - val_precision: 0.9771 - val_recall: 0.9723 - val_auc: 0.9982 - val_prc: 0.9939\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0312 - accuracy: 0.9905 - precision: 0.9917 - recall: 0.9889 - auc: 0.9999 - prc: 0.9995 - val_loss: 0.0876 - val_accuracy: 0.9744 - val_precision: 0.9772 - val_recall: 0.9728 - val_auc: 0.9979 - val_prc: 0.9938\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0263 - accuracy: 0.9924 - precision: 0.9933 - recall: 0.9916 - auc: 0.9999 - prc: 0.9996 - val_loss: 0.0880 - val_accuracy: 0.9751 - val_precision: 0.9768 - val_recall: 0.9733 - val_auc: 0.9978 - val_prc: 0.9931\n",
      "Epoch 1/10\n",
      "480/480 [==============================] - 4s 5ms/step - loss: 0.3636 - accuracy: 0.9177 - precision: 0.9525 - recall: 0.8801 - auc: 0.9941 - prc: 0.9709 - val_loss: 0.1802 - val_accuracy: 0.9497 - val_precision: 0.9622 - val_recall: 0.9365 - val_auc: 0.9969 - val_prc: 0.9862\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.1675 - accuracy: 0.9518 - precision: 0.9629 - recall: 0.9414 - auc: 0.9972 - prc: 0.9872 - val_loss: 0.1353 - val_accuracy: 0.9597 - val_precision: 0.9690 - val_recall: 0.9521 - val_auc: 0.9979 - val_prc: 0.9914\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.1147 - accuracy: 0.9665 - precision: 0.9740 - recall: 0.9601 - auc: 0.9985 - prc: 0.9933 - val_loss: 0.1094 - val_accuracy: 0.9660 - val_precision: 0.9719 - val_recall: 0.9612 - val_auc: 0.9986 - val_prc: 0.9935\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0861 - accuracy: 0.9744 - precision: 0.9795 - recall: 0.9697 - auc: 0.9991 - prc: 0.9960 - val_loss: 0.0966 - val_accuracy: 0.9709 - val_precision: 0.9752 - val_recall: 0.9667 - val_auc: 0.9986 - val_prc: 0.9945\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0689 - accuracy: 0.9795 - precision: 0.9830 - recall: 0.9759 - auc: 0.9994 - prc: 0.9972 - val_loss: 0.0930 - val_accuracy: 0.9713 - val_precision: 0.9757 - val_recall: 0.9682 - val_auc: 0.9985 - val_prc: 0.9943\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0550 - accuracy: 0.9840 - precision: 0.9867 - recall: 0.9811 - auc: 0.9996 - prc: 0.9982 - val_loss: 0.0841 - val_accuracy: 0.9749 - val_precision: 0.9781 - val_recall: 0.9718 - val_auc: 0.9986 - val_prc: 0.9948\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0455 - accuracy: 0.9860 - precision: 0.9886 - recall: 0.9839 - auc: 0.9997 - prc: 0.9987 - val_loss: 0.0867 - val_accuracy: 0.9747 - val_precision: 0.9773 - val_recall: 0.9726 - val_auc: 0.9984 - val_prc: 0.9943\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0386 - accuracy: 0.9882 - precision: 0.9901 - recall: 0.9862 - auc: 0.9998 - prc: 0.9991 - val_loss: 0.0852 - val_accuracy: 0.9731 - val_precision: 0.9756 - val_recall: 0.9719 - val_auc: 0.9983 - val_prc: 0.9942\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0317 - accuracy: 0.9908 - precision: 0.9920 - recall: 0.9896 - auc: 0.9998 - prc: 0.9993 - val_loss: 0.0898 - val_accuracy: 0.9730 - val_precision: 0.9754 - val_recall: 0.9718 - val_auc: 0.9978 - val_prc: 0.9931\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0287 - accuracy: 0.9915 - precision: 0.9924 - recall: 0.9903 - auc: 0.9999 - prc: 0.9994 - val_loss: 0.0848 - val_accuracy: 0.9750 - val_precision: 0.9778 - val_recall: 0.9737 - val_auc: 0.9981 - val_prc: 0.9940\n",
      "Epoch 1/10\n",
      "480/480 [==============================] - 3s 5ms/step - loss: 0.3709 - accuracy: 0.9149 - precision: 0.9510 - recall: 0.8784 - auc: 0.9938 - prc: 0.9696 - val_loss: 0.1904 - val_accuracy: 0.9433 - val_precision: 0.9586 - val_recall: 0.9327 - val_auc: 0.9966 - val_prc: 0.9849\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.1690 - accuracy: 0.9504 - precision: 0.9624 - recall: 0.9391 - auc: 0.9973 - prc: 0.9872 - val_loss: 0.1365 - val_accuracy: 0.9613 - val_precision: 0.9698 - val_recall: 0.9516 - val_auc: 0.9978 - val_prc: 0.9910\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.1197 - accuracy: 0.9651 - precision: 0.9731 - recall: 0.9579 - auc: 0.9985 - prc: 0.9928 - val_loss: 0.1113 - val_accuracy: 0.9664 - val_precision: 0.9736 - val_recall: 0.9603 - val_auc: 0.9986 - val_prc: 0.9933\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0926 - accuracy: 0.9727 - precision: 0.9783 - recall: 0.9678 - auc: 0.9990 - prc: 0.9953 - val_loss: 0.1029 - val_accuracy: 0.9682 - val_precision: 0.9741 - val_recall: 0.9643 - val_auc: 0.9984 - val_prc: 0.9936\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 2s 5ms/step - loss: 0.0730 - accuracy: 0.9783 - precision: 0.9825 - recall: 0.9739 - auc: 0.9993 - prc: 0.9968 - val_loss: 0.1014 - val_accuracy: 0.9700 - val_precision: 0.9736 - val_recall: 0.9661 - val_auc: 0.9983 - val_prc: 0.9937\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0574 - accuracy: 0.9836 - precision: 0.9862 - recall: 0.9808 - auc: 0.9995 - prc: 0.9980 - val_loss: 0.0921 - val_accuracy: 0.9729 - val_precision: 0.9764 - val_recall: 0.9702 - val_auc: 0.9981 - val_prc: 0.9937\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0476 - accuracy: 0.9859 - precision: 0.9879 - recall: 0.9837 - auc: 0.9998 - prc: 0.9987 - val_loss: 0.0866 - val_accuracy: 0.9751 - val_precision: 0.9785 - val_recall: 0.9730 - val_auc: 0.9983 - val_prc: 0.9944\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0404 - accuracy: 0.9881 - precision: 0.9899 - recall: 0.9866 - auc: 0.9998 - prc: 0.9990 - val_loss: 0.0874 - val_accuracy: 0.9747 - val_precision: 0.9771 - val_recall: 0.9724 - val_auc: 0.9984 - val_prc: 0.9945\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0322 - accuracy: 0.9902 - precision: 0.9918 - recall: 0.9889 - auc: 0.9999 - prc: 0.9994 - val_loss: 0.0887 - val_accuracy: 0.9746 - val_precision: 0.9770 - val_recall: 0.9734 - val_auc: 0.9980 - val_prc: 0.9941\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 2s 4ms/step - loss: 0.0283 - accuracy: 0.9915 - precision: 0.9924 - recall: 0.9904 - auc: 0.9999 - prc: 0.9996 - val_loss: 0.0912 - val_accuracy: 0.9728 - val_precision: 0.9751 - val_recall: 0.9711 - val_auc: 0.9978 - val_prc: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>prc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989500</td>\n",
       "      <td>0.990056</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>0.997627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991214</td>\n",
       "      <td>0.992128</td>\n",
       "      <td>0.990214</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.998029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.990786</td>\n",
       "      <td>0.991986</td>\n",
       "      <td>0.990286</td>\n",
       "      <td>0.999485</td>\n",
       "      <td>0.998425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.990429</td>\n",
       "      <td>0.991344</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.999243</td>\n",
       "      <td>0.997764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989643</td>\n",
       "      <td>0.990413</td>\n",
       "      <td>0.988786</td>\n",
       "      <td>0.999416</td>\n",
       "      <td>0.998479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall       auc       prc\n",
       "0  0.989500   0.990056  0.988500  0.999160  0.997627\n",
       "1  0.991214   0.992128  0.990214  0.999299  0.998029\n",
       "2  0.990786   0.991986  0.990286  0.999485  0.998425\n",
       "3  0.990429   0.991344  0.989857  0.999243  0.997764\n",
       "4  0.989643   0.990413  0.988786  0.999416  0.998479"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "# create resources required\n",
    "x = np.concatenate((X0, X1), axis=0)\n",
    "y = np.concatenate((L0, L1), axis=0)\n",
    "kfold = KFold(n_splits=NUM_FOLDS, shuffle=True)\n",
    "\n",
    "results_table = []\n",
    "\n",
    "def score_to_json(fold_num, scores):\n",
    "    # 0th index is the loss\n",
    "    return {x.name: scores[i+1] for i, x in enumerate(MODEL_PERFORMANCE_METRICS)}\n",
    "\n",
    "for fold_num, data in enumerate(kfold.split(x, y)):\n",
    "    # train your model\n",
    "    train, test = data\n",
    "    model, history = train_mlp(create_mlp())\n",
    "\n",
    "    # evaluate your model\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    \n",
    "    # record it for results\n",
    "    results_table.append(score_to_json(fold_num + 1, scores))\n",
    "\n",
    "# view your results over n folds\n",
    "results_table = pd.json_normalize(results_table)\n",
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>prc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.990314</td>\n",
       "      <td>0.991185</td>\n",
       "      <td>0.989529</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.998065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy  precision    recall       auc       prc\n",
       "mean  0.990314   0.991185  0.989529  0.999320  0.998065\n",
       "std   0.000735   0.000926  0.000831  0.000131  0.000382"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table.describe().loc[['mean','std']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
